{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe65642-4ada-4085-b64e-2425962ac19a",
   "metadata": {},
   "source": [
    "<h1>DATA LOADING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79cf139-0d7e-481e-b4d4-fa5c1b5188e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36ca702-4e29-4887-8c27-a861eada2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('apartment_export_20250502_041108.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b3aaad-a018-4a4e-ad6c-beaa75103ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = [\n",
    "    'Чиланзарский район', 'Юнусабадский район', 'Янгихаётский район',\n",
    "    'Яккасарайский район', 'Шайхантахурский район',\n",
    "    'Мирабадский район', 'Учтепинский район', 'Яшнабадский район',\n",
    "    'Бектемирский район', 'Сергелийский район',\n",
    "    'Мирзо-Улугбекский район', 'Алмазарский район', 'Новый Ташкентский район'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame where district_name matches any of the districts\n",
    "tashkent_df = df[df['district_name'].isin(districts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ff4a5a-5fbe-4e91-be44-21b6b30a0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[43. 63. nan ... 58. 70. 47.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1. 3. 3. ... 2. 3. 2.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4. 2. 6. ... 5. 1. 2.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 5.  4. 16. ...  5.  4.  4.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[18797441. 14829776.  8662104. ... 14925012.       nan       nan]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
      "/var/folders/p1/5vh1vyrn3c91hc6lp5yz185m0000gn/T/ipykernel_7180/1874548450.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[8.082900e+08 9.342759e+08 7.492720e+08 ...          nan          nan\n",
      "          nan]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Unknown' with NaN in specific columns using .loc[]\n",
    "columns_to_replace_unknown = ['foundation_name', 'layout_name', 'repair_name', 'wc_name']\n",
    "tashkent_df.loc[:, columns_to_replace_unknown] = tashkent_df[columns_to_replace_unknown].replace('Unknown', np.nan)\n",
    "\n",
    "# Replace values <= 0 with NaN in specific columns using .loc[]\n",
    "columns_to_check = ['total_area', 'number_of_rooms', 'floors', 'total_floors', \n",
    "                    'price_per_sqm', 'price', 'usd_uzs_rate']\n",
    "tashkent_df.loc[:, columns_to_check] = tashkent_df[columns_to_check].apply(lambda x: np.where(x <= 0, np.nan, x))\n",
    "tashkent_df = tashkent_df.drop(['city_name', 'region_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2745df5b-3921-43eb-8b92-f1b0d7c21c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tashkent_df = tashkent_df.dropna(subset=['price', 'floors', 'number_of_rooms', 'total_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b282e71c-d983-41ae-ba92-f6a09dc69e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = ['foundation_name', 'layout_name', 'repair_name', 'wc_name']\n",
    "\n",
    "def fill_missing_with_mode(df, columns, group_by='district_name'):\n",
    "    for column in columns:\n",
    "        mode_values = df.groupby(group_by)[column].agg(lambda x: x.mode()[0] if not x.mode().empty else None)\n",
    "        \n",
    "        global_mode = df[column].mode()[0] if not df[column].mode().empty else None\n",
    "        \n",
    "        df[column] = df.apply(\n",
    "            lambda row: mode_values[row[group_by]] if pd.isna(row[column]) and mode_values[row[group_by]] is not None \n",
    "                       else (global_mode if pd.isna(row[column]) else row[column]),\n",
    "            axis=1\n",
    "        )\n",
    "    return df\n",
    "\n",
    "tashkent_df = fill_missing_with_mode(tashkent_df, columns_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347f132b-e768-4921-afd0-98e7eebef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing_stage = tashkent_df.copy()\n",
    "df_preprocessing_stage['price_usd'] = df_preprocessing_stage['price'] / df_preprocessing_stage['usd_uzs_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbf59cf-9c0e-4e99-b59a-f039bf8c213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repair_name_mapping = {\n",
    "    'evro': 'Евроремонт',\n",
    "    'sredniy': 'Средний',\n",
    "    'chernovaya': 'Черновая отделка',\n",
    "    'custom':'Авторский проект',\n",
    "    'kapital':'Капитал'\n",
    "}\n",
    "\n",
    "df_preprocessing_stage['repair_name'] = df_preprocessing_stage['repair_name'].replace(repair_name_mapping)\n",
    "df_preprocessing_stage['year_month'] = df_preprocessing_stage['datetime'].dt.to_period('M')\n",
    "df_preprocessing_stage = df_preprocessing_stage.drop(['apartment_id', 'usd_uzs_rate', 'price', 'datetime', 'price_per_sqm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af506b06-d801-4649-b553-07f5e5f2dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing_stage = df_preprocessing_stage[df_preprocessing_stage['floors'] <= df_preprocessing_stage['total_floors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f43172-9b16-401b-9d5d-d96a4ed19700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 221433 entries, 5 to 283370\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count   Dtype    \n",
      "---  ------           --------------   -----    \n",
      " 0   district_name    221433 non-null  object   \n",
      " 1   type_of_market   221433 non-null  object   \n",
      " 2   foundation_name  221433 non-null  object   \n",
      " 3   layout_name      221433 non-null  object   \n",
      " 4   repair_name      221433 non-null  object   \n",
      " 5   wc_name          221433 non-null  object   \n",
      " 6   total_area       221433 non-null  float64  \n",
      " 7   number_of_rooms  221433 non-null  float64  \n",
      " 8   floors           221433 non-null  float64  \n",
      " 9   total_floors     221433 non-null  float64  \n",
      " 10  price_usd        221433 non-null  float64  \n",
      " 11  year_month       221433 non-null  period[M]\n",
      "dtypes: float64(5), object(6), period[M](1)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_preprocessing_stage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ac3607-6771-41ba-8e8a-9ccde876b7b2",
   "metadata": {},
   "source": [
    "<h2>HISTOGRAMS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee00296-9ffd-458b-899a-81d091859048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_check = ['total_area', 'number_of_rooms', 'floors', 'total_floors', 'price_usd']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(columns_to_check), figsize=(20, 10))\n",
    "\n",
    "# Plot each column\n",
    "for i, column in enumerate(columns_to_check):\n",
    "    axes[i].hist(df_preprocessing_stage[column], bins=20, color='blue', alpha=0.7)\n",
    "    axes[i].set_title(column)\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a006f-8740-4a2c-8bed-aada92df1d22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>CORRELATION MATRIX</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283d0c4-fd11-4406-8a6d-7d6835ee3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the columns to check\n",
    "columns_to_check = ['total_area', 'number_of_rooms', 'floors', 'total_floors', 'price_usd']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_preprocessing_stage[columns_to_check].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4af88-1931-4cc6-a64a-5bf0cf5d0139",
   "metadata": {},
   "source": [
    "<h1>OUTLIER ELEMINATION PIPELINE</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb3f97-4893-49e7-a9f2-38a0cca06637",
   "metadata": {},
   "source": [
    "<h2>FILTRATION DEPARTING FROM BUSINESS CASE PERSPECTIVE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ddc4ab-6b21-4d4c-a163-df84aa490d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_area</th>\n",
       "      <th>number_of_rooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>total_floors</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>214039.000000</td>\n",
       "      <td>214039.000000</td>\n",
       "      <td>214039.000000</td>\n",
       "      <td>214039.000000</td>\n",
       "      <td>2.140390e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>87.886226</td>\n",
       "      <td>2.485374</td>\n",
       "      <td>4.390401</td>\n",
       "      <td>7.122552</td>\n",
       "      <td>1.059089e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1066.158380</td>\n",
       "      <td>0.999654</td>\n",
       "      <td>2.702202</td>\n",
       "      <td>3.254768</td>\n",
       "      <td>2.513391e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.388539e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.813833e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.787845e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.150458e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.161223e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          total_area  number_of_rooms         floors   total_floors  \\\n",
       "count  214039.000000    214039.000000  214039.000000  214039.000000   \n",
       "mean       87.886226         2.485374       4.390401       7.122552   \n",
       "std      1066.158380         0.999654       2.702202       3.254768   \n",
       "min         1.000000         1.000000       1.000000       1.000000   \n",
       "25%        49.000000         2.000000       2.000000       4.000000   \n",
       "50%        63.000000         2.000000       4.000000       7.000000   \n",
       "75%        81.000000         3.000000       6.000000       9.000000   \n",
       "max    100000.000000         7.000000      16.000000      16.000000   \n",
       "\n",
       "          price_usd  \n",
       "count  2.140390e+05  \n",
       "mean   1.059089e+05  \n",
       "std    2.513391e+06  \n",
       "min    1.388539e-02  \n",
       "25%    5.813833e+04  \n",
       "50%    7.787845e+04  \n",
       "75%    1.150458e+05  \n",
       "max    1.161223e+09  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing_stage = df_preprocessing_stage[\n",
    "    (df_preprocessing_stage['number_of_rooms'] <= 7) &\n",
    "    (df_preprocessing_stage['total_floors'] <= 16)\n",
    "]\n",
    "df_preprocessing_stage.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e9771-f3f5-477b-a1de-4e4ff66c546c",
   "metadata": {},
   "source": [
    "<h2>FUNCTION DEFINED</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543a9219-fdaa-41a4-8619-7169421b7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, permutations\n",
    "\n",
    "\n",
    "# Outlier elimination methods\n",
    "def eliminate_outliers_zscore(df, column, threshold=3):\n",
    "    return df[np.abs(zscore(df[column])) < threshold]\n",
    "\n",
    "\n",
    "def eliminate_outliers_iqr(df, column):\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "\n",
    "def eliminate_outliers_isolation_forest(df, column, contamination=0.01):\n",
    "    isolation_forest = IsolationForest(contamination=contamination, random_state=42)\n",
    "    df['Outlier_Flag'] = isolation_forest.fit_predict(df[[column]])\n",
    "    df = df[df['Outlier_Flag'] == 1]\n",
    "    return df.drop(columns=['Outlier_Flag'])\n",
    "\n",
    "\n",
    "def eliminate_outliers_quantile_clipping(df, column, lower_quantile=0.01, upper_quantile=0.99):\n",
    "    lower_bound = df[column].quantile(lower_quantile)\n",
    "    upper_bound = df[column].quantile(upper_quantile)\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "\n",
    "def eliminate_outliers_mad(df, column, threshold=3):\n",
    "    median = df[column].median()\n",
    "    mad = np.median(np.abs(df[column] - median))\n",
    "    df['MAD_Score'] = np.abs(df[column] - median) / (mad + 1e-9)\n",
    "    df = df[df['MAD_Score'] < threshold]\n",
    "    return df.drop(columns=['MAD_Score'])\n",
    "\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "def apply_one_hot_encoding(df, categorical_columns):\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "    for col in df_encoded.select_dtypes(include=['bool']).columns:\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Linear regression function\n",
    "def linear_regression_analysis(df, y_axis, dataset_title):\n",
    "    X = df.drop(columns=[y_axis])\n",
    "    y = df[y_axis]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MSE': mse, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d63ed7-d2d6-4b61-b8e9-13cb1ce16202",
   "metadata": {},
   "source": [
    "<h2>FUNCTION EXECUTION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7d10464-9b51-43f1-a002-f6e618200e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_analysis(processed_df, target_column, pipeline_name):\n",
    "    X = processed_df.drop(columns=[target_column])\n",
    "    y = processed_df[target_column]\n",
    "    \n",
    "    metrics = random_forest(X, y)\n",
    "    \n",
    "    metrics['Pipeline_Sequence'] = pipeline_name\n",
    "    return metrics\n",
    "\n",
    "def evaluate_all_combinations_permutations_rf(df, target_column, categorical_columns):\n",
    "    # Columns to clean\n",
    "    columns_to_clean = ['total_area', 'price_usd']\n",
    "    \n",
    "    outlier_methods = {\n",
    "        'IQR': eliminate_outliers_iqr,\n",
    "        'Isolation Forest': eliminate_outliers_isolation_forest,\n",
    "        'Quantile Clipping': eliminate_outliers_quantile_clipping,\n",
    "        'MAD': eliminate_outliers_mad\n",
    "    }\n",
    "    \n",
    "    column_orders = list(permutations(columns_to_clean))\n",
    "    \n",
    "    method_combinations = list(product(outlier_methods.items(), repeat=len(columns_to_clean)))\n",
    "    \n",
    "    results = []  \n",
    "    count = 0\n",
    "\n",
    "    for column_order in column_orders:\n",
    "        for method_sequence in method_combinations:\n",
    "            processed_df = df.copy()\n",
    "            column_max_values = {} \n",
    "            \n",
    "            for column, (method_name, method) in zip(column_order, method_sequence):\n",
    "                try:\n",
    "                    processed_df = method(processed_df, column)\n",
    "                    column_max_values[column] = processed_df[column].max()  \n",
    "                except Exception as e:\n",
    "                    print(f\"Error applying method {method_name} to column {column}: {e}\")\n",
    "                    column_max_values[column] = None  \n",
    "            \n",
    "            row_count_after_elimination = len(processed_df)\n",
    "            \n",
    "            processed_df = apply_one_hot_encoding(processed_df, categorical_columns)\n",
    "            \n",
    "            metrics = random_forest_analysis(processed_df, target_column, \"Combination Pipeline\")\n",
    "            metrics['Pipeline_Sequence'] = \" -> \".join([f\"{method_name}({column})\" for column, (method_name, _) in zip(column_order, method_sequence)])\n",
    "            metrics['Column_Order'] = \" -> \".join(column_order)\n",
    "            \n",
    "            for column, max_value in column_max_values.items():\n",
    "                metrics[f\"Max_{column}\"] = max_value\n",
    "            \n",
    "            metrics['Row_Count_After_Outlier_Elimination'] = row_count_after_elimination\n",
    "            \n",
    "            results.append(metrics)\n",
    "            count += 1\n",
    "            print(f\"SEQ: {count}/{len(column_orders) * len(method_combinations)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b3abb5-705a-46f0-a6db-6e3ef6df838d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m categorical_columns_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfoundation_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepair_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwc_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m result_df_6_rf \u001b[38;5;241m=\u001b[39m evaluate_all_combinations_permutations_rf(df\u001b[38;5;241m=\u001b[39mdf_preprocessing_stage, target_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_usd\u001b[39m\u001b[38;5;124m'\u001b[39m,categorical_columns\u001b[38;5;241m=\u001b[39mcategorical_columns_list)\n",
      "Cell \u001b[0;32mIn[16], line 45\u001b[0m, in \u001b[0;36mevaluate_all_combinations_permutations_rf\u001b[0;34m(df, target_column, categorical_columns)\u001b[0m\n\u001b[1;32m     41\u001b[0m row_count_after_elimination \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(processed_df)\n\u001b[1;32m     43\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m apply_one_hot_encoding(processed_df, categorical_columns)\n\u001b[0;32m---> 45\u001b[0m metrics \u001b[38;5;241m=\u001b[39m random_forest_analysis(processed_df, target_column, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombination Pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPipeline_Sequence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column, (method_name, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(column_order, method_sequence)])\n\u001b[1;32m     47\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn_Order\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(column_order)\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mrandom_forest_analysis\u001b[0;34m(processed_df, target_column, pipeline_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m processed_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_column])\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m processed_df[target_column]\n\u001b[0;32m----> 5\u001b[0m metrics \u001b[38;5;241m=\u001b[39m random_forest(X, y)\n\u001b[1;32m      7\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPipeline_Sequence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pipeline_name\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_forest' is not defined"
     ]
    }
   ],
   "source": [
    "categorical_columns_list = ['district_name', 'foundation_name', 'layout_name','repair_name', 'wc_name', 'year_month']\n",
    "result_df_6_rf = evaluate_all_combinations_permutations_rf(df=df_preprocessing_stage, target_column = 'price_usd',categorical_columns=categorical_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a0d2d342-fcb0-4311-943d-f09c7d3169f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_6_rf.to_excel('outputs_excel_rf.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad755110-741d-4001-879b-8d923b778d40",
   "metadata": {},
   "source": [
    "<h2>APPLY OUTLIER ELEMINATION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb327380-97f4-41cc-8d98-7383b80f5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_selected_sequence(df, categorical_columns):\n",
    "    cleaning_sequence = [\n",
    "        ('total_area', 'Quantile Clipping', eliminate_outliers_quantile_clipping),\n",
    "        ('price_usd', 'Quantile Clipping', eliminate_outliers_quantile_clipping)\n",
    "    ]\n",
    "\n",
    "    processed_df = df.copy()\n",
    "\n",
    "    for column, method_name, method in cleaning_sequence:\n",
    "        try:\n",
    "            processed_df = method(processed_df, column)\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying method {method_name} to column {column}: {e}\")\n",
    "            continue  # Skip this column if there's an error\n",
    "\n",
    "    processed_df = apply_one_hot_encoding(processed_df, categorical_columns)\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "categorical_columns_list = ['district_name', 'foundation_name', 'layout_name','repair_name', 'wc_name', 'year_month']\n",
    "cleaned_df = evaluate_selected_sequence(df_preprocessing_stage, categorical_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e2c21-72a5-4259-a054-5456b2110d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a413a62-1c5d-494f-8599-f72c295368e8",
   "metadata": {},
   "source": [
    "<h3>GRID SEARCH</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993e1cf-043c-414f-893c-ecdf524bbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import VotingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2\n",
    "    }\n",
    "\n",
    "\n",
    "# Modified function with loss visualization\n",
    "def optimized_model_with_kfold_and_loss(model, X, y, param_grid=None, model_name=\"Model\"):\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # 5 folds\n",
    "    if param_grid:\n",
    "        # Grid Search Optimization with K-Fold\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=kfold, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        # No Grid Search, only K-Fold\n",
    "        best_model = model\n",
    "        for train_idx, val_idx in kfold.split(X_train):\n",
    "            best_model.fit(X_train[train_idx], y_train[train_idx])\n",
    "            val_pred = best_model.predict(X_train[val_idx])\n",
    "\n",
    "    # Fit on the entire training set with best model\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    return calculate_metrics(y_test, y_test_pred), best_model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cfe42-b385-408d-9467-d62445915f89",
   "metadata": {},
   "source": [
    "<h3>Traditional ML</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524d353-a89f-48ff-8920-7af02fc8045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_decision_tree(X, y):\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model_name = \"DecisionTree\"\n",
    "    model = DecisionTreeRegressor(random_state=23)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n",
    "\n",
    "def optimized_random_forest(X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    model_name = \"RandomForest\"\n",
    "    model = RandomForestRegressor(random_state=23)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n",
    "\n",
    "def optimized_knn(X, y):\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "    model_name = \"KNN\"\n",
    "    model = KNeighborsRegressor()\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604fad27-8eaf-46b4-a8e4-ae5d3137fa24",
   "metadata": {},
   "source": [
    "<h3>Ensemble Methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a547467-2803-4181-9043-211e9bbfcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_xgboost(X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "    model_name = \"XGBoost\"\n",
    "    model = XGBRegressor(random_state=23)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n",
    "\n",
    "def optimized_catboost(X, y):\n",
    "    param_grid = {\n",
    "        'iterations': [100, 200],\n",
    "        'depth': [3, 5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "    model_name = \"CatBoost\"\n",
    "    model = CatBoostRegressor(silent=True, random_state=23)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n",
    "\n",
    "def optimized_lightgbm(X, y):\n",
    "    from lightgbm import LGBMRegressor\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [20, 31, 50]\n",
    "    }\n",
    "    model_name = \"LightGBM\"\n",
    "    model = LGBMRegressor(random_state=23)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbc9b9-46f3-4a66-80d7-e3ac9f87ef86",
   "metadata": {},
   "source": [
    "<h3>ANN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f427e48-f3a5-4916-9aff-dc92441a0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_mlp(X, y):\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "    model_name = \"MLP\"\n",
    "    model = MLPRegressor(random_state=23, max_iter=500)\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(model, X, y, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n",
    "\n",
    "def optimized_lstm(X, y, timesteps):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM, Dense\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import numpy as np\n",
    "\n",
    "    # Reshaping data for LSTM model\n",
    "    X_reshaped = np.array([X[i:i+timesteps] for i in range(len(X) - timesteps)])\n",
    "    y_reshaped = y[timesteps:]\n",
    "\n",
    "    def build_model(units, learning_rate):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units, input_shape=(timesteps, X.shape[1])))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', learning_rate=learning_rate)\n",
    "        return model\n",
    "\n",
    "    param_grid = {\n",
    "        'units': [50, 100],\n",
    "        'learning_rate': [0.01, 0.001]\n",
    "    }\n",
    "    model_name = \"LSTM\"\n",
    "    # Implementing a wrapper or using GridSearchCV with Keras models\n",
    "    metrics, best_model = optimized_model_with_kfold_and_loss(build_model, X_reshaped, y_reshaped, param_grid=param_grid, model_name=model_name)\n",
    "    return metrics, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaec4d-ecf1-4f59-9f93-8e29d4aab4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_metrics, dt_best_model = optimized_decision_tree(X, y)\n",
    "# random_forrest_metircs, rf_best_model = optimized_random_forest(X, y)\n",
    "# knn_metrics, knn_best_model = optimized_knn(X, y)\n",
    "# xgboost_metrics, xgboost_best_model = optimized_xgboost(X, y)\n",
    "# catboost_metrics, catboost_model = optimized_catboost(X, y)\n",
    "\n",
    "\n",
    "models_measurement_optimized = {}\n",
    "\n",
    "#Traditional ML\n",
    "models_measurement_optimized['Decision Tree'] = decision_tree_metrics\n",
    "# models_measurement['Random Forrest'] = random_forrest_metircs\n",
    "# models_measurement['KNN'] = knn_metrics\n",
    "# models_measurement['XGBoost'] = xgboost_metrics\n",
    "# models_measurement['CatBoost'] = catboost_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c75b0-d434-4b01-b7e7-d913d1d1726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_metrics, lstm_best_model = optimized_mlp(X, y)(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
