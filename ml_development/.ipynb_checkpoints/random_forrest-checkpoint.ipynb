{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77620cb9-272f-455b-90a0-1e531b199149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cleaned_df = pd.read_excel('clean_data_for_ml_training.xlsx', index_col=None)\n",
    "cleaned_df = cleaned_df.drop(['Unnamed: 0'], axis=1)\n",
    "X = cleaned_df.drop(columns=['price_usd'])\n",
    "y = cleaned_df['price_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518c202-cefe-485d-8ac2-bf59f65ac1f6",
   "metadata": {},
   "source": [
    "<h1>Bayesian optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ad94e-a616-47e2-a2d2-d7ffaeac6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, 'pkls/scaler.pkl')\n",
    "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2\n",
    "    }\n",
    "\n",
    "def random_forest_bayesian_tuning(X, y):\n",
    "    print(\"Preprocessing data...\")\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "\n",
    "    param_space = {\n",
    "        'n_estimators': Integer(100, 1000),\n",
    "        'max_depth': Integer(3, 30),\n",
    "        'min_samples_split': Integer(2, 20),\n",
    "        'min_samples_leaf': Integer(1, 10),\n",
    "        'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "        'oob_score': Categorical([True, False]),\n",
    "        'criterion': Categorical(['squared_error']),\n",
    "        'max_samples': Real(0.5, 1.0),\n",
    "        'min_weight_fraction_leaf': Real(0.0, 0.5),\n",
    "        'max_leaf_nodes': Integer(10, 100),\n",
    "        'ccp_alpha': Real(0.0, 0.05),\n",
    "        'warm_start': Categorical([False])  \n",
    "    }\n",
    "\n",
    "    rf_model = RandomForestRegressor(random_state=23)\n",
    "\n",
    "    opt = BayesSearchCV(\n",
    "        estimator=rf_model,\n",
    "        search_spaces=param_space,\n",
    "        n_iter=30,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Starting Bayesian optimization...\")\n",
    "    opt.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Optimization finished.\")\n",
    "    print(\"Best Parameters:\", opt.best_params_)\n",
    "\n",
    "    best_model = opt.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    return metrics, best_model, opt.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777ec31-2fcc-4f21-ac66-3e4e3db661f9",
   "metadata": {},
   "source": [
    "<h1>Model implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d26a4-fe62-4938-962a-30578d757501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_forest_with_loss(X, y):\n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
    "    train_mse_values = []\n",
    "    test_mse_values = []\n",
    "    n_trees = range(1, 101)    param_grid = {\n",
    "        'n_estimators': 100,  \n",
    "        'max_depth': 30,  \n",
    "        'min_samples_split': 2,  \n",
    "        'min_samples_leaf': 10,  \n",
    "        'max_features': None,  \n",
    "        'oob_score': True,  \n",
    "        'criterion': 'squared_error',  \n",
    "        'max_samples': None,  \n",
    "        'min_weight_fraction_leaf': 0.0,  \n",
    "        'max_leaf_nodes': 100,  \n",
    "        'warm_start': False, \n",
    "        'ccp_alpha': 0.05,  \n",
    "    }\n",
    "\n",
    "    \n",
    "    for i, n in enumerate(n_trees):        model = RandomForestRegressor(n_estimators=n, \n",
    "                                      max_depth=param_grid['max_depth'],\n",
    "                                      min_samples_split=param_grid['min_samples_split'],\n",
    "                                      min_samples_leaf=param_grid['min_samples_leaf'],\n",
    "                                      max_features=param_grid['max_features'],\n",
    "                                      oob_score=param_grid['oob_score'],\n",
    "                                      criterion=param_grid['criterion'],\n",
    "                                      max_samples=param_grid['max_samples'],\n",
    "                                      min_weight_fraction_leaf=param_grid['min_weight_fraction_leaf'],\n",
    "                                      max_leaf_nodes=param_grid['max_leaf_nodes'],\n",
    "                                      warm_start=param_grid['warm_start'],\n",
    "                                      ccp_alpha=param_grid['ccp_alpha'],\n",
    "                                      random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_values.append(train_mse)\n",
    "        test_mse_values.append(test_mse)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Completed {i + 1}/{len(n_trees)} iterations. {len(n_trees) - (i + 1)} left.\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_trees, train_mse_values, label=\"Train MSE\", marker='o')\n",
    "    plt.plot(n_trees, test_mse_values, label=\"Test MSE\", marker='o')\n",
    "    plt.title(\"Loss (MSE) vs Number of Trees\")\n",
    "    plt.xlabel(\"Number of Trees\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44b433-8a1e-4268-95cf-8d04fa8ba7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics, rf_best_model, rf_best_params = random_forest_with_loss(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9fcf0-8252-4ada-b648-2976f9c70046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data_single_entry(X):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "def prepare_input(incoming_data: pd.DataFrame, expected_columns: list) -> pd.DataFrame:\n",
    "    categorical_cols = ['district_name', 'foundation_name', 'layout_name', 'repair_name', 'wc_name']\n",
    "    incoming_encoded = pd.get_dummies(incoming_data, columns=categorical_cols)\n",
    "\n",
    "    # Add missing columns\n",
    "    for col in expected_columns:\n",
    "        if col not in incoming_encoded.columns:\n",
    "            incoming_encoded[col] = 0\n",
    "\n",
    "    incoming_encoded = incoming_encoded[[col for col in expected_columns]]\n",
    "\n",
    "    incoming_encoded = incoming_encoded[expected_columns]\n",
    "\n",
    "    incoming_encoded = incoming_encoded.astype(int)\n",
    "\n",
    "    return incoming_encoded\n",
    "\n",
    "def predict_with_confidence(model, X_row: pd.DataFrame) -> dict:\n",
    "    all_preds = [tree.predict(X_row)[0] for tree in model.estimators_]\n",
    "    mean_pred = sum(all_preds) / len(all_preds)\n",
    "    std_pred = pd.Series(all_preds).std()\n",
    "    return {\n",
    "        'prediction': mean_pred,\n",
    "        'lower_bound': mean_pred - 1 * std_pred,\n",
    "        'upper_bound': mean_pred + 1 * std_pred,\n",
    "        'std_dev': std_pred,\n",
    "        'all_pred': all_preds\n",
    "    }\n",
    "\n",
    "model = rf_best_model\n",
    "expected_columns = X.columns\n",
    "\n",
    "incoming_data = pd.DataFrame([{\n",
    "    \"district_name\": \"Чиланзарский район\",\n",
    "    \"number_of_rooms\": \"2\",\n",
    "    \"floors\": \"4\",\n",
    "    \"total_floors\": \"4\",\n",
    "    \"total_area\": \"20\",\n",
    "    \"foundation_name\": \"Панельный\",\n",
    "    \"layout_name\": \"Смежно-раздельная\",\n",
    "    \"wc_name\": \"2 санузла и более\",\n",
    "    \"repair_name\": \"Евроремонт\",\n",
    "    \"year\": 2024,\n",
    "    \"month\":11,\n",
    "    \"is_primary\": \"1\"\n",
    "}])\n",
    "\n",
    "scaler = joblib.load('pkls/scaler.pkl')\n",
    "processed_input = prepare_input(incoming_data, expected_columns)\n",
    "scaled_input = scaler.transform(processed_input)  # Apply MinMaxScaler\n",
    "result = predict_with_confidence(model, scaled_input)\n",
    "\n",
    "print(f\"Prediction: {result['prediction']:.2f}\")\n",
    "print(f\"Confidence Interval (approx. 95%): {result['lower_bound']:.2f} to {result['upper_bound']:.2f}\")\n",
    "print(f\"Standard Deviation: {result['std_dev']:.2f}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = result['all_pred']\n",
    "\n",
    "plt.hist(data, bins=10, edgecolor='black') \n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of result[\\'all_pred\\']')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
